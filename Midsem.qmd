---
title: "Midterm Answers 13-16"
author: "Namit Shrivastava"
format: pdf
---

```{r setup}
library(tidyverse)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(performance)
theme_set(theme_minimal())
```

```{r data-load}
sust_eff <- readr::read_csv("/Users/namomac/Desktop/SURV-687/sust_eff.csv", show_col_types = FALSE)
glimpse(sust_eff)
summary(select(sust_eff, math, female, minority, grade, lowinc_cen))
```

# Question 13

```{r q13-model}
model13 <- lmer(math ~ female + grade + lowinc_cen + minority + (1 | schoolid), data = sust_eff)
summary(model13)
```

**Intercept (–1.686)**
This is the predicted math score for a baseline student i.e. a male, non-minority in grade 0 at a school whose low-income percentage is average (because lowinc_cen is centered). Now, although I think grade 0 isn’t an actual grade, but I am guessing this intercept anchors the scale for the other effects.

**Female (+0.031)**
Now, holding grade, minority status, and school composition constant, I estimate that girls score about 0.03 points higher than boys. That small positive difference isn’t statistically significant here as p value is around 0.17, so I can’t be confident this gender gap differs from zero.

**Grade (+0.803)**
Here, this shows that each additional grade level corresponds to an average increase of 0.80 points on the math scale, assuming gender, minority status, and school context stay the same. This large, highly significant effect reflects steady learning gains as students move through grades.

**lowinc_cen (–0.008)**
Ok so from what I can interpret, for each one‐unit increase in the centered percentage of low-income students (i.e., a school with one percentage-point more low-income peers than average), student math scores drop by about 0.008 points on average, all else equal. Hence, this small but significant negative association suggests schools with higher proportions of low-income students tend to have slightly lower math scores.

**Minority (–0.399)**
Now, after controlling for grade, gender, and school income composition, minority students score on average 0.40 points lower than non-minority students. Since, this difference is highly significant, so, it indicates a persistent achievement gap in this dataset.

# Question 14
```{r q14-model}
model14 <- lmer(math ~ female + grade + lowinc_cen + minority + (1 + minority | schoolid), data = sust_eff, control = lmerControl(optimizer = "bobyqa"))
summary(model14)
```

```{r q14-test}
model14_comp <- anova(model13, model14)
model14_comp
pvalue_q14 <- model14_comp$`Pr(>Chisq)`[2]
df_q14 <- model14_comp$Df[2] - model14_comp$Df[1]
list(p_value = pvalue_q14, df = df_q14)
```

## Hypothesis Test

So I conducted a likelihood-ratio test to evaluate whether there is significant between-school variability in the effect of minority status.

### Hypotheses

$$
H_0: \sigma^2_{\text{minority}} = 0 \quad \text{(No between-school variability)} \\
H_A: \sigma^2_{\text{minority}} > 0 \quad \text{(Presence of between-school variability)}
$$

### Test Results

The test yielded the following statistics:

$$
\chi^2(2) = 51.01, \quad p \approx 8.4 \times 10^{-12}
$$

Since the p-value is much smaller than the conventional threshold of 0.05 ($p \ll 0.05$), I will **reject the null hypothesis**.

### Interpretation

This result provides strong evidence of significant between-school variability in the effect of minority status. In other words, the **minority achievement gap differs meaningfully across schools**, suggesting that school-level factors may influence how minority status affects academic outcomes.

# Question 15

```{r q15-model}
# 1. Converting the preferred REML model to ML
best_model_reml <- if (pvalue_q14 < 0.05) model14 else model13
best_model_ml   <- update(best_model_reml, REML = FALSE)

# 2. Fitting the reduced model (drop 'female')
model15_ml <- update(best_model_ml, . ~ . - female)

# 3. Likelihood‐ratio test
lr15 <- anova(best_model_ml, model15_ml)
print(lr15)

# 4. Restoring REML for diagnostics on the chosen model
preferred_model <- if (lr15$`Pr(>Chisq)`[2] < 0.05) best_model_reml else update(best_model_reml, . ~ . - female)

# This will show residuals, random effects, QQ plots, etc.
check_model(preferred_model, check = c("normality", "linearity", "homoscedasticity", "outliers", "random_effects"))
```

## Model Comparison

So now I compared two machine learning–fitted models to assess the impact of including a fixed effect for female.

### Likelihood-Ratio Test

The likelihood-ratio test yielded the following result:

$$
\chi^2(1) = 1.88, \quad p = 0.17
$$

Since the p-value exceeds the conventional threshold of 0.05 ($p > 0.05$), I can conclude that **dropping the fixed effect for female does not significantly reduce model fit**.

### Model Preference

Given this result, the simpler model i.e. without the fixed effect for female, is preferred due to its parsimony.

### Diagnostic Checks

In the preferred model:

- Residuals are approximately **normal** and **homoscedastic**
- The **random-effects distribution** is symmetric

# Question 16

Refit the preferred model, adding the interaction between `lowinc_cen` and `minority`, and interpret whether the interaction explains variation in minority slopes across schools.

```{r q16-model}
model16_ml <- update(best_model_ml, . ~ . + lowinc_cen:minority)
lr16 <- anova(best_model_ml, model16_ml)
lr16
pvalue_q16 <- lr16$`Pr(>Chisq)`[2]
df_q16 <- lr16$Df[2] - lr16$Df[1]
list(p_value = pvalue_q16, df = df_q16)
```

```{r q16-fit}
model16 <- update(best_model_reml, . ~ . + lowinc_cen:minority)
summary(model16)
interaction_effect <- fixef(model16)["lowinc_cen:minority"]
pvalue_interaction <- summary(model16)$coef["lowinc_cen:minority", "Pr(>|t|)"]
```

## Model Comparison: Interaction Term

Now, I evaluated whether the interaction between a school's centered low-income percentage and minority status significantly affects math scores.

### Likelihood-Ratio Test

To compare the model with and without the interaction term, I conducted a likelihood-ratio test:

$$
\chi^2(1) = 0.25, \quad p = 0.62
$$

### REML t-Test for Interaction Coefficient

The restricted maximum likelihood (REML) estimate for the interaction term is:

$$
\hat{\beta}_{\text{lowin}:\text{minority}} = 0.00149, \quad p = 0.62
$$

Since the p-value is much greater than the conventional threshold of 0.05 ($p \gg 0.05$), I can conclude that the interaction is **not statistically significant**.

### Interpretation

So I can say that for each one-unit increase in a school’s centered low-income percentage, the math-score gap between minority and non-minority students changes by only about **0.0015 points**. This effect is both **tiny** and **statistically insignificant**, suggesting that the proportion of low-income students does **not meaningfully alter** the minority achievement gap in this sample.