---
title: "Midterm Answers 13-16"
author: "Namit Shrivastava"
format: pdf
---

```{r setup}
library(tidyverse)
library(lme4)
library(lmerTest)
library(broom.mixed)
library(performance)
theme_set(theme_minimal())
```

```{r data-load}
sust_eff <- readr::read_csv("/Users/namomac/Desktop/SURV-687/sust_eff.csv", show_col_types = FALSE)
glimpse(sust_eff)
summary(select(sust_eff, math, female, minority, grade, lowinc_cen))
```

# Question 13

```{r q13-model}
model13 <- lmer(math ~ female + grade + lowinc_cen + minority + (1 | schoolid), data = sust_eff)
summary(model13)
```

**Intercept (–1.686)**
This is the predicted math score for a baseline student i.e. a male, non-minority in grade 0 at a school whose low-income percentage is average (because lowinc_cen is centered). Now, although I think grade 0 isn’t an actual grade, but I am guessing this intercept anchors the scale for the other effects.

**Female (+0.031)**
Now, holding grade, minority status, and school composition constant, I estimate that girls score about 0.03 points higher than boys. That small positive difference isn’t statistically significant here as p value is around 0.17, so I can’t be confident this gender gap differs from zero.

**Grade (+0.803)**
Here, this shows that each additional grade level corresponds to an average increase of 0.80 points on the math scale, assuming gender, minority status, and school context stay the same. This large, highly significant effect reflects steady learning gains as students move through grades.

**lowinc_cen (–0.008)**
Ok so from what I can interpret, for each one‐unit increase in the centered percentage of low-income students (i.e., a school with one percentage-point more low-income peers than average), student math scores drop by about 0.008 points on average, all else equal. Hence, this small but significant negative association suggests schools with higher proportions of low-income students tend to have slightly lower math scores.

**Minority (–0.399)**
Now, after controlling for grade, gender, and school income composition, minority students score on average 0.40 points lower than non-minority students. Since, this difference is highly significant, so, it indicates a persistent achievement gap in this dataset.

# Question 14

Refit the model with a random slope for `minority` and test whether the variance of the random slopes differs from zero.

```{r q14-model}
model14 <- lmer(math ~ female + grade + lowinc_cen + minority + (1 + minority | schoolid), data = sust_eff, control = lmerControl(optimizer = "bobyqa"))
summary(model14)
```

```{r q14-test}
model14_comp <- anova(model13, model14)
model14_comp
pvalue_q14 <- model14_comp$`Pr(>Chisq)`[2]
df_q14 <- model14_comp$Df[2] - model14_comp$Df[1]
list(p_value = pvalue_q14, df = df_q14)
```

## Hypothesis Test

So I conducted a likelihood-ratio test to evaluate whether there is significant between-school variability in the effect of minority status.

### Hypotheses

$$
H_0: \sigma^2_{\text{minority}} = 0 \quad \text{(No between-school variability)} \\
H_A: \sigma^2_{\text{minority}} > 0 \quad \text{(Presence of between-school variability)}
$$

### Test Results

The test yielded the following statistics:

$$
\chi^2(2) = 51.01, \quad p \approx 8.4 \times 10^{-12}
$$

Since the p-value is much smaller than the conventional threshold of 0.05 ($p \ll 0.05$), I will **reject the null hypothesis**.

### Interpretation

This result provides strong evidence of significant between-school variability in the effect of minority status. In other words, the **minority achievement gap differs meaningfully across schools**, suggesting that school-level factors may influence how minority status affects academic outcomes.

# Question 15

Select the better model from Questions 13 and 14 (based on the test above) and refit it without the fixed effect of `female`. Compare model fit and examine diagnostics for the preferred model.

```{r q15-models}
best_model_reml <- if (pvalue_q14 < 0.05) model14 else model13
best_model_ml <- update(best_model_reml, REML = FALSE)
model15_ml <- update(best_model_ml, . ~ . - female)
lr15 <- anova(model15_ml, best_model_ml)
lr15
pvalue_q15 <- lr15$`Pr(>Chisq)`[2]
df_q15 <- lr15$Df[2] - lr15$Df[1]
list(p_value = pvalue_q15, df = df_q15)
```

```{r q15-fit}
preferred_model <- if (pvalue_q15 < 0.05) best_model_reml else update(best_model_reml, . ~ . - female)
summary(preferred_model)
```

```{r q15-diagnostics, fig.height=4, fig.width=6}
check_model(preferred_model)
```

The likelihood ratio comparison (χ²(`r df_q15`) = `r round(lr15$Chisq[2], 2)`, p = `r signif(pvalue_q15, 3)`) indicates that removing `female` results in a `r ifelse(pvalue_q15 < 0.05, "significant", "non-significant")` loss of fit. Because of this, I `r ifelse(pvalue_q15 < 0.05, "retain", "drop")` the `female` fixed effect in the preferred model for interpretation and diagnostics. The diagnostic plots suggest that the residuals are approximately normally distributed with no major pattern in the residual-versus-fitted plot, and the random effects appear reasonably symmetric, so the model assumptions seem appropriate.

# Question 16

Refit the preferred model, adding the interaction between `lowinc_cen` and `minority`, and interpret whether the interaction explains variation in minority slopes across schools.

```{r q16-model}
model16_ml <- update(best_model_ml, . ~ . + lowinc_cen:minority)
lr16 <- anova(best_model_ml, model16_ml)
lr16
pvalue_q16 <- lr16$`Pr(>Chisq)`[2]
df_q16 <- lr16$Df[2] - lr16$Df[1]
list(p_value = pvalue_q16, df = df_q16)
```

```{r q16-fit}
model16 <- update(best_model_reml, . ~ . + lowinc_cen:minority)
summary(model16)
interaction_effect <- fixef(model16)["lowinc_cen:minority"]
pvalue_interaction <- summary(model16)$coef["lowinc_cen:minority", "Pr(>|t|)"]
```

The interaction between `lowinc_cen` and `minority` yields χ²(`r df_q16`) = `r round(lr16$Chisq[2], 2)` with p = `r signif(pvalue_q16, 3)`, so the interaction is `r ifelse(pvalue_q16 < 0.05, "statistically significant", "not statistically significant")` when added to the fixed effects. The estimated coefficient of `r round(interaction_effect, 3)` (t = `r round(summary(model16)$coef["lowinc_cen:minority", "t value"], 2)`, df ≈ `r round(summary(model16)$coef["lowinc_cen:minority", "df"], 1)`) indicates that for each one-unit increase in a school's centered low-income percentage, the difference in math scores between minority and non-minority students changes by approximately `r round(interaction_effect, 3)` points. Even when the interaction is not statistically significant, the direction and magnitude of the estimate still provide insight into how school context might moderate minority students' math performance relative to their peers.
